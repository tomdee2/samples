{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Evaluation - Understanding How Agents Think and Execute Tasks\n",
    "\n",
    "This tutorial demonstrates how to evaluate agent trajectories - the sequences of tool calls, reasoning steps, and decisions agents make to complete tasks. Trajectory evaluation helps you understand not just what agents produce, but how they think and execute tasks.\n",
    "\n",
    "### What You'll Learn\n",
    "- Understand agent trajectories (tool calls, reasoning steps, sequences)\n",
    "- Visualize execution trajectories (Session → Trace → Spans)\n",
    "- Use TrajectoryEvaluator with custom rubrics\n",
    "- Evaluate optimal, suboptimal, and incorrect trajectories\n",
    "- Implement trajectory scoring functions (exact_match, in_order, any_order)\n",
    "- Analyze HOW agents think, not just WHAT they produce\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                       |\n",
    "|:--------------------|:----------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Intermediate - Understanding and evaluating agent execution paths                 |\n",
    "| Tutorial components | Multi-agent system, TrajectoryEvaluator, trajectory visualization                |\n",
    "| Tutorial vertical   | Agent Evaluation                                                                  |\n",
    "| Example complexity  | Medium                                                                            |\n",
    "| SDK used            | Strands Agents, Strands Evals                                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Understanding Trajectories\n\nA **trajectory** is the complete sequence of actions an agent takes to solve a task, including tool calls, reasoning steps, and execution flow.\n\n#### Why Evaluate Trajectories?\n\n| Output Evaluation Alone | Trajectory Evaluation Adds |\n|:------------------------|:---------------------------|\n| Multiple paths can produce same output | Shows efficiency of execution |\n| Can't detect inefficient reasoning | Reveals correctness of tool usage |\n| Misses optimization opportunities | Identifies where agent can improve |\n\nUse trajectory evaluation during development, optimization, and production monitoring to validate agent design and detect reasoning quality degradation.\n\n#### Trajectory Hierarchy\n\n```\nSession → Trace (per invocation) → Spans (individual steps: tool calls, LLM calls)\n```\n\n#### Three Trajectory Scenarios\n\n| Scenario | Description | Characteristics |\n|:---------|:------------|:----------------|\n| Optimal | Correct tools in correct order | Efficient, minimal steps, expected behavior |\n| Suboptimal | Extra or redundant steps | Correct answer but inefficient, redundant calls |\n| Incorrect | Wrong tools or wrong order | May produce wrong output, requires fixes |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Configure AWS region and model settings for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import boto3\n",
    "\n",
    "# AWS Configuration (inline - no config.py)\n",
    "session = boto3.Session()\n",
    "AWS_REGION = session.region_name or 'us-east-1'\n",
    "DEFAULT_MODEL = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Imports\n",
    "\n",
    "Import all necessary libraries for agent creation, trajectory evaluation, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Standard imports\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Strands imports\n",
    "from strands import Agent\n",
    "from strands.multiagent import GraphBuilder\n",
    "\n",
    "# Strands Evals imports\n",
    "from strands_evals import Experiment, Case\n",
    "from strands_evals.evaluators import TrajectoryEvaluator\n",
    "\n",
    "# Display utilities\n",
    "from IPython.display import Markdown, display"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Multi-Agent System for Trajectory Analysis\n\nWe'll create a multi-agent business decision system with parallel execution. This system demonstrates clear trajectory patterns as different agents collaborate on analysis tasks.\n\n#### Architecture\n\n```\nfinancial_advisor (entry)\n     ├──> technical_architect ──┐\n     └──> market_researcher ────┴──> risk_analyst (final)\n```\n\n#### Agent Code\n\nMulti-agent code adapted from: /strands-samples/01-tutorials/02-multi-agent-systems/03-graph-agent/"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create specialized agents for parallel analysis\n",
    "financial_advisor = Agent(\n",
    "    name=\"financial_advisor\",\n",
    "    system_prompt=\"You are a financial advisor focused on cost-benefit analysis, budget implications, and ROI calculations. Provide concise financial assessment in 2-3 sentences.\",\n",
    "    model=DEFAULT_MODEL\n",
    ")\n",
    "\n",
    "technical_architect = Agent(\n",
    "    name=\"technical_architect\",\n",
    "    system_prompt=\"You are a technical architect who evaluates feasibility, implementation challenges, and technical risks. Provide concise technical assessment in 2-3 sentences.\",\n",
    "    model=DEFAULT_MODEL\n",
    ")\n",
    "\n",
    "market_researcher = Agent(\n",
    "    name=\"market_researcher\",\n",
    "    system_prompt=\"You are a market researcher who analyzes market conditions, user needs, and competitive landscape. Provide concise market assessment in 2-3 sentences.\",\n",
    "    model=DEFAULT_MODEL\n",
    ")\n",
    "\n",
    "risk_analyst = Agent(\n",
    "    name=\"risk_analyst\",\n",
    "    system_prompt=\"You are a risk analyst who synthesizes input from finance, technical, and market experts to identify potential risks and provide a final recommendation in 2-3 sentences.\",\n",
    "    model=DEFAULT_MODEL\n",
    ")\n",
    "\n",
    "# Build the agent graph with parallel execution\n",
    "builder = GraphBuilder()\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(financial_advisor, \"finance_expert\")\n",
    "builder.add_node(technical_architect, \"tech_expert\")\n",
    "builder.add_node(market_researcher, \"market_expert\")\n",
    "builder.add_node(risk_analyst, \"risk_analyst\")\n",
    "\n",
    "# Add edges - parallel execution pattern\n",
    "builder.add_edge(\"finance_expert\", \"tech_expert\")\n",
    "builder.add_edge(\"finance_expert\", \"market_expert\")\n",
    "builder.add_edge(\"tech_expert\", \"risk_analyst\")\n",
    "builder.add_edge(\"market_expert\", \"risk_analyst\")\n",
    "\n",
    "# Set entry point\n",
    "builder.set_entry_point(\"finance_expert\")\n",
    "\n",
    "# Build the graph\n",
    "decision_graph = builder.build()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Multi-Agent System\n",
    "\n",
    "Before evaluating trajectories, let's verify the system works and examine its execution flow."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test the multi-agent system\n",
    "test_query = \"Should we invest $500K in developing an AI-powered customer service chatbot?\"\n",
    "result = decision_graph(test_query)\n",
    "\n",
    "print(f\"\\nFinal Decision: {result}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show execution flow\n",
    "print(\"\\nExecution Order (Trajectory):\")\n",
    "for node in result.execution_order:\n",
    "    print(f\"  - {node.node_id}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Understanding Trajectory Scoring Functions\n\n| Scorer | Use Case | Scoring Logic |\n|:-------|:---------|:--------------|\n| **Exact Match** | Strict compliance (medical, financial) | 1.0 if exact sequence, 0.0 otherwise |\n| **In-Order Match** | Sequence matters, extra steps OK | Proportion of expected steps in correct order |\n| **Any-Order Match** | Only presence matters | Proportion of expected steps present |\n\n#### Implementation"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def exact_match_scorer(expected_trajectory: List[str], actual_trajectory: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Score 1.0 if trajectories match exactly, 0.0 otherwise.\n",
    "    \n",
    "    Args:\n",
    "        expected_trajectory: List of expected step identifiers\n",
    "        actual_trajectory: List of actual step identifiers from execution\n",
    "    \n",
    "    Returns:\n",
    "        1.0 if exact match, 0.0 otherwise\n",
    "    \"\"\"\n",
    "    return 1.0 if expected_trajectory == actual_trajectory else 0.0\n",
    "\n",
    "\n",
    "def in_order_match_scorer(expected_trajectory: List[str], actual_trajectory: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Score based on proportion of expected steps present in correct order.\n",
    "    Extra steps are allowed but don't affect score.\n",
    "    \n",
    "    Args:\n",
    "        expected_trajectory: List of expected step identifiers\n",
    "        actual_trajectory: List of actual step identifiers from execution\n",
    "    \n",
    "    Returns:\n",
    "        Proportion of expected steps found in order (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    if not expected_trajectory:\n",
    "        return 1.0\n",
    "    \n",
    "    expected_idx = 0\n",
    "    matches = 0\n",
    "    \n",
    "    for actual_step in actual_trajectory:\n",
    "        if expected_idx < len(expected_trajectory) and actual_step == expected_trajectory[expected_idx]:\n",
    "            matches += 1\n",
    "            expected_idx += 1\n",
    "    \n",
    "    return matches / len(expected_trajectory)\n",
    "\n",
    "\n",
    "def any_order_match_scorer(expected_trajectory: List[str], actual_trajectory: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Score based on proportion of expected steps present, regardless of order.\n",
    "    \n",
    "    Args:\n",
    "        expected_trajectory: List of expected step identifiers\n",
    "        actual_trajectory: List of actual step identifiers from execution\n",
    "    \n",
    "    Returns:\n",
    "        Proportion of expected steps found (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    if not expected_trajectory:\n",
    "        return 1.0\n",
    "    \n",
    "    actual_set = set(actual_trajectory)\n",
    "    matches = sum(1 for step in expected_trajectory if step in actual_set)\n",
    "    \n",
    "    return matches / len(expected_trajectory)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Extraction Helper\n",
    "\n",
    "Create a helper function to extract trajectories from agent execution results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def extract_trajectory(result) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract the execution trajectory from a graph result.\n",
    "    \n",
    "    Args:\n",
    "        result: Graph execution result\n",
    "    \n",
    "    Returns:\n",
    "        List of node IDs in execution order\n",
    "    \"\"\"\n",
    "    return [node.node_id for node in result.execution_order]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Optimal Trajectory\n",
    "\n",
    "An optimal trajectory uses the correct tools in the correct order with minimal steps. This represents the expected, efficient execution path.\n",
    "\n",
    "#### Expected Trajectory\n",
    "```\n",
    "finance_expert → tech_expert → market_expert → risk_analyst\n",
    "```\n",
    "\n",
    "This is the natural flow for our multi-agent decision system."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define optimal test case\n",
    "optimal_case = Case(\n",
    "    name=\"Optimal Decision Path\",\n",
    "    input=\"Should we invest $1M in expanding our cloud infrastructure to support 10x user growth?\",\n",
    "    expected_output=\"A comprehensive analysis considering financial, technical, and market factors with a clear recommendation.\"\n",
    ")\n",
    "\n",
    "# Expected trajectory for this case\n",
    "expected_optimal_trajectory = [\n",
    "    \"finance_expert\",\n",
    "    \"tech_expert\",\n",
    "    \"market_expert\",\n",
    "    \"risk_analyst\"\n",
    "]\n",
    "\n",
    "print(f\"\\nExpected trajectory: {' → '.join(expected_optimal_trajectory)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Execute the optimal case\n",
    "optimal_result = decision_graph(optimal_case.input)\n",
    "optimal_trajectory = extract_trajectory(optimal_result)\n",
    "\n",
    "print(f\"\\nInput: {optimal_case.input}\")\n",
    "print(f\"\\nFinal Output: {optimal_result}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nTrajectory Analysis:\")\n",
    "print(f\"  Expected: {' → '.join(expected_optimal_trajectory)}\")\n",
    "print(f\"  Actual:   {' → '.join(optimal_trajectory)}\")\n",
    "\n",
    "# Score the trajectory\n",
    "exact_score = exact_match_scorer(expected_optimal_trajectory, optimal_trajectory)\n",
    "in_order_score = in_order_match_scorer(expected_optimal_trajectory, optimal_trajectory)\n",
    "any_order_score = any_order_match_scorer(expected_optimal_trajectory, optimal_trajectory)\n",
    "\n",
    "print(f\"\\nTrajectory Scores:\")\n",
    "print(f\"  Exact Match:    {exact_score:.2f} (requires exact sequence)\")\n",
    "print(f\"  In-Order Match: {in_order_score:.2f} (allows extra steps)\")\n",
    "print(f\"  Any-Order Match: {any_order_score:.2f} (ignores order)\")\n",
    "\n",
    "# Interpretation\n",
    "if exact_score == 1.0:\n",
    "    interpretation = \"**OPTIMAL**: Trajectory perfectly matches expected path\"\n",
    "elif in_order_score >= 0.75:\n",
    "    interpretation = \"**GOOD**: Most expected steps present in correct order\"\n",
    "else:\n",
    "    interpretation = \"**SUBOPTIMAL**: Significant deviations from expected path\"\n",
    "\n",
    "print(f\"\\nInterpretation: {interpretation}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Suboptimal Trajectory\n",
    "\n",
    "A suboptimal trajectory reaches the correct answer but takes unnecessary steps or makes redundant tool calls. This might indicate inefficiency or confusion in the agent's decision-making.\n",
    "\n",
    "#### Simulation Note\n",
    "Since our graph agent follows a deterministic execution pattern, we'll simulate a suboptimal trajectory by analyzing what it would look like if the agent made redundant calls."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Simulate a suboptimal trajectory scenario\n",
    "suboptimal_case = Case(\n",
    "    name=\"Suboptimal Decision Path - Extra Analysis Steps\",\n",
    "    input=\"Evaluate a $250K investment in updating our mobile app with new features.\",\n",
    "    expected_output=\"A comprehensive analysis with clear recommendation.\"\n",
    ")\n",
    "\n",
    "# Expected optimal trajectory\n",
    "expected_suboptimal_trajectory = [\n",
    "    \"finance_expert\",\n",
    "    \"tech_expert\",\n",
    "    \"market_expert\",\n",
    "    \"risk_analyst\"\n",
    "]\n",
    "\n",
    "# Simulate what a suboptimal trajectory might look like with redundant steps\n",
    "# In a real scenario, this might happen if agent repeats analysis or backtracks\n",
    "simulated_suboptimal_trajectory = [\n",
    "    \"finance_expert\",\n",
    "    \"finance_expert\",  # Redundant call\n",
    "    \"tech_expert\",\n",
    "    \"market_expert\",\n",
    "    \"market_expert\",   # Redundant call\n",
    "    \"risk_analyst\"\n",
    "]\n",
    "\n",
    "print(\"Suboptimal trajectory scenario defined\")\n",
    "print(f\"\\nExpected optimal: {' → '.join(expected_suboptimal_trajectory)}\")\n",
    "print(f\"Simulated actual: {' → '.join(simulated_suboptimal_trajectory)}\")\n",
    "print(\"\\nNote: Simulated trajectory shows redundant calls to finance_expert and market_expert\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyze the suboptimal trajectory\n",
    "print(f\"\\nCase: {suboptimal_case.name}\")\n",
    "print(f\"Input: {suboptimal_case.input}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nTrajectory Analysis:\")\n",
    "print(f\"  Expected: {' → '.join(expected_suboptimal_trajectory)}\")\n",
    "print(f\"  Simulated: {' → '.join(simulated_suboptimal_trajectory)}\")\n",
    "\n",
    "# Score the simulated trajectory\n",
    "exact_score = exact_match_scorer(expected_suboptimal_trajectory, simulated_suboptimal_trajectory)\n",
    "in_order_score = in_order_match_scorer(expected_suboptimal_trajectory, simulated_suboptimal_trajectory)\n",
    "any_order_score = any_order_match_scorer(expected_suboptimal_trajectory, simulated_suboptimal_trajectory)\n",
    "\n",
    "print(f\"\\nTrajectory Scores:\")\n",
    "print(f\"  Exact Match:    {exact_score:.2f} (requires exact sequence)\")\n",
    "print(f\"  In-Order Match: {in_order_score:.2f} (allows extra steps)\")\n",
    "print(f\"  Any-Order Match: {any_order_score:.2f} (ignores order)\")\n",
    "\n",
    "# Analysis\n",
    "analysis = \"\"\"\n",
    "**Analysis of Suboptimal Trajectory:**\n",
    "\n",
    "- **Exact Match: 0.00** - Trajectory doesn't match expected sequence exactly\n",
    "- **In-Order Match: 1.00** - All expected steps are present in correct order (redundant steps ignored)\n",
    "- **Any-Order Match: 1.00** - All expected steps are present\n",
    "\n",
    "**Key Observations:**\n",
    "- Redundant calls to finance_expert (called twice)\n",
    "- Redundant calls to market_expert (called twice)\n",
    "- Total steps: 6 (expected 4)\n",
    "- Efficiency: 67% (4/6 necessary steps)\n",
    "\n",
    "**Impact:**\n",
    "- Increased latency (extra LLM calls)\n",
    "- Higher costs (more token usage)\n",
    "- Correct final output but inefficient path\n",
    "\n",
    "**Recommendations:**\n",
    "- Investigate why redundant calls occur\n",
    "- Add caching or memoization for repeated analyses\n",
    "- Review agent orchestration logic\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(analysis))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Incorrect Trajectory\n",
    "\n",
    "An incorrect trajectory uses wrong tools or wrong order, potentially leading to incorrect outputs. This might indicate fundamental issues with agent design or understanding.\n",
    "\n",
    "#### Simulation Note\n",
    "We'll simulate an incorrect trajectory where the agent skips critical analysis steps or uses tools in wrong order."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Simulate an incorrect trajectory scenario\n",
    "incorrect_case = Case(\n",
    "    name=\"Incorrect Decision Path - Missing Critical Analysis\",\n",
    "    input=\"Should we acquire a competitor for $5M?\",\n",
    "    expected_output=\"A comprehensive analysis covering all decision factors.\"\n",
    ")\n",
    "\n",
    "# Expected optimal trajectory\n",
    "expected_incorrect_trajectory = [\n",
    "    \"finance_expert\",\n",
    "    \"tech_expert\",\n",
    "    \"market_expert\",\n",
    "    \"risk_analyst\"\n",
    "]\n",
    "\n",
    "# Simulate what an incorrect trajectory might look like\n",
    "# Missing market analysis and jumping straight to risk assessment\n",
    "simulated_incorrect_trajectory = [\n",
    "    \"finance_expert\",\n",
    "    \"risk_analyst\",     # Wrong: skipped technical and market analysis\n",
    "    \"tech_expert\"       # Wrong: analyzing after making risk decision\n",
    "]\n",
    "\n",
    "print(\"Incorrect trajectory scenario defined\")\n",
    "print(f\"\\nExpected: {' → '.join(expected_incorrect_trajectory)}\")\n",
    "print(f\"Simulated: {' → '.join(simulated_incorrect_trajectory)}\")\n",
    "print(\"\\nNote: Simulated trajectory skips market_expert and analyzes in wrong order\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyze the incorrect trajectory\n",
    "print(f\"\\nCase: {incorrect_case.name}\")\n",
    "print(f\"Input: {incorrect_case.input}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nTrajectory Analysis:\")\n",
    "print(f\"  Expected: {' → '.join(expected_incorrect_trajectory)}\")\n",
    "print(f\"  Simulated: {' → '.join(simulated_incorrect_trajectory)}\")\n",
    "\n",
    "# Score the simulated trajectory\n",
    "exact_score = exact_match_scorer(expected_incorrect_trajectory, simulated_incorrect_trajectory)\n",
    "in_order_score = in_order_match_scorer(expected_incorrect_trajectory, simulated_incorrect_trajectory)\n",
    "any_order_score = any_order_match_scorer(expected_incorrect_trajectory, simulated_incorrect_trajectory)\n",
    "\n",
    "print(f\"\\nTrajectory Scores:\")\n",
    "print(f\"  Exact Match:    {exact_score:.2f} (requires exact sequence)\")\n",
    "print(f\"  In-Order Match: {in_order_score:.2f} (allows extra steps)\")\n",
    "print(f\"  Any-Order Match: {any_order_score:.2f} (ignores order)\")\n",
    "\n",
    "# Analysis\n",
    "analysis = \"\"\"\n",
    "**Analysis of Incorrect Trajectory:**\n",
    "\n",
    "- **Exact Match: 0.00** - Completely different sequence\n",
    "- **In-Order Match: 0.50** - Only 2 of 4 expected steps present in order (finance_expert, tech_expert)\n",
    "- **Any-Order Match: 0.50** - Only 2 of 4 expected steps present (missing market_expert)\n",
    "\n",
    "**Key Observations:**\n",
    "- **Missing step**: market_expert analysis completely skipped\n",
    "- **Wrong order**: risk_analyst called before tech_expert\n",
    "- **Incomplete analysis**: Decision made without market perspective\n",
    "- Coverage: 50% (2/4 critical analyses performed)\n",
    "\n",
    "**Critical Issues:**\n",
    "1. **Missing market analysis**: No competitive or demand assessment\n",
    "2. **Premature risk decision**: Made before gathering all inputs\n",
    "3. **Wrong execution order**: Technical analysis after risk assessment is too late\n",
    "\n",
    "**Impact:**\n",
    "- **High risk**: Decision made without complete information\n",
    "- **Low confidence**: Missing critical market perspective\n",
    "- **Potential errors**: Risk analysis based on incomplete data\n",
    "\n",
    "**Recommendations:**\n",
    "- **Critical fix required**: Ensure all required analyses are performed\n",
    "- Review orchestration logic to enforce dependencies\n",
    "- Add validation checks before risk assessment\n",
    "- Consider making market analysis a hard requirement\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(analysis))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Evaluation with TrajectoryEvaluator\n",
    "\n",
    "Now let's use the built-in TrajectoryEvaluator to automatically evaluate trajectories. The TrajectoryEvaluator uses LLM-based assessment to score trajectory quality."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create custom rubric for trajectory evaluation\n",
    "trajectory_rubric = \"\"\"\n",
    "Evaluate the agent's execution trajectory based on the following criteria:\n",
    "\n",
    "Score 1 (Poor):\n",
    "- Missing critical analysis steps\n",
    "- Wrong order of operations\n",
    "- Skipped essential expert consultations\n",
    "- Incomplete information gathering\n",
    "\n",
    "Score 2 (Fair):\n",
    "- Some required steps present but incomplete\n",
    "- Partially correct order\n",
    "- Missing one key analysis\n",
    "- Redundant or inefficient steps\n",
    "\n",
    "Score 3 (Good):\n",
    "- Most required steps present\n",
    "- Generally correct order\n",
    "- Minor inefficiencies acceptable\n",
    "- All critical analyses performed\n",
    "\n",
    "Score 4 (Very Good):\n",
    "- All required steps present\n",
    "- Correct order maintained\n",
    "- Efficient execution\n",
    "- Proper expert collaboration\n",
    "\n",
    "Score 5 (Excellent):\n",
    "- Optimal execution path\n",
    "- Perfect order and completeness\n",
    "- No unnecessary steps\n",
    "- Maximum efficiency and correctness\n",
    "\"\"\"\n",
    "\n",
    "# Create TrajectoryEvaluator with custom rubric\n",
    "trajectory_evaluator = TrajectoryEvaluator(\n",
    "    rubric=trajectory_rubric,\n",
    "    model=DEFAULT_MODEL, \n",
    "    include_inputs=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create evaluation dataset with all three scenarios\n",
    "evaluation_cases = [\n",
    "    optimal_case,\n",
    "    suboptimal_case,\n",
    "    incorrect_case\n",
    "]\n",
    "\n",
    "dataset = Experiment(\n",
    "    cases=evaluation_cases,\n",
    "    evaluators=[trajectory_evaluator]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define agent task function for evaluation\n",
    "def agent_task(case: Case) -> dict:\n",
    "    \"\"\"\n",
    "    Execute the multi-agent decision system and return the result with trajectory.\n",
    "    \"\"\"\n",
    "    result = decision_graph(case.input)\n",
    "    \n",
    "    return {\n",
    "        \"output\": str(result),\n",
    "        \"trajectory\": [node.node_id for node in result.execution_order]\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run trajectory evaluation\n",
    "report = dataset.run_evaluations(agent_task)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results\n",
    "\n",
    "Display the trajectory evaluation results with detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display evaluation report\n",
    "report[0].run_display()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Trajectory Metrics\n",
    "\n",
    "Let's create a summary visualization comparing all three trajectory scenarios."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compile trajectory metrics for comparison\n",
    "trajectories_summary = [\n",
    "    {\n",
    "        \"scenario\": \"Optimal\",\n",
    "        \"expected\": expected_optimal_trajectory,\n",
    "        \"actual\": optimal_trajectory,\n",
    "        \"exact_match\": exact_match_scorer(expected_optimal_trajectory, optimal_trajectory),\n",
    "        \"in_order_match\": in_order_match_scorer(expected_optimal_trajectory, optimal_trajectory),\n",
    "        \"any_order_match\": any_order_match_scorer(expected_optimal_trajectory, optimal_trajectory),\n",
    "        \"efficiency\": len(expected_optimal_trajectory) / len(optimal_trajectory) if optimal_trajectory else 0\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Suboptimal\",\n",
    "        \"expected\": expected_suboptimal_trajectory,\n",
    "        \"actual\": simulated_suboptimal_trajectory,\n",
    "        \"exact_match\": exact_match_scorer(expected_suboptimal_trajectory, simulated_suboptimal_trajectory),\n",
    "        \"in_order_match\": in_order_match_scorer(expected_suboptimal_trajectory, simulated_suboptimal_trajectory),\n",
    "        \"any_order_match\": any_order_match_scorer(expected_suboptimal_trajectory, simulated_suboptimal_trajectory),\n",
    "        \"efficiency\": len(expected_suboptimal_trajectory) / len(simulated_suboptimal_trajectory)\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Incorrect\",\n",
    "        \"expected\": expected_incorrect_trajectory,\n",
    "        \"actual\": simulated_incorrect_trajectory,\n",
    "        \"exact_match\": exact_match_scorer(expected_incorrect_trajectory, simulated_incorrect_trajectory),\n",
    "        \"in_order_match\": in_order_match_scorer(expected_incorrect_trajectory, simulated_incorrect_trajectory),\n",
    "        \"any_order_match\": any_order_match_scorer(expected_incorrect_trajectory, simulated_incorrect_trajectory),\n",
    "        \"efficiency\": len([s for s in simulated_incorrect_trajectory if s in expected_incorrect_trajectory]) / len(expected_incorrect_trajectory)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create comparison table\n",
    "comparison_md = \"\"\"\n",
    "## Trajectory Comparison Summary\n",
    "\n",
    "| Scenario | Exact Match | In-Order Match | Any-Order Match | Efficiency |\n",
    "|:---------|:------------|:---------------|:----------------|:-----------|\n",
    "\"\"\"\n",
    "\n",
    "for t in trajectories_summary:\n",
    "    comparison_md += f\"| {t['scenario']} | {t['exact_match']:.2f} | {t['in_order_match']:.2f} | {t['any_order_match']:.2f} | {t['efficiency']:.2%} |\\n\"\n",
    "\n",
    "comparison_md += \"\"\"\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "**Optimal Trajectory:**\n",
    "- Perfect scores across all metrics (1.00)\n",
    "- 100% efficiency - no wasted steps\n",
    "- Represents ideal execution pattern\n",
    "\n",
    "**Suboptimal Trajectory:**\n",
    "- Exact match fails due to extra steps\n",
    "- In-order and any-order matches are perfect (1.00)\n",
    "- 67% efficiency due to redundant calls\n",
    "- Correct but inefficient execution\n",
    "\n",
    "**Incorrect Trajectory:**\n",
    "- All metrics show significant degradation\n",
    "- Only 50% of expected steps present\n",
    "- 50% efficiency - missing critical analyses\n",
    "- Represents problematic execution requiring fixes\n",
    "\n",
    "### Choosing the Right Scorer\n",
    "\n",
    "**Use Exact Match when:**\n",
    "- Strict compliance is required (medical, financial)\n",
    "- Regulatory requirements demand specific steps\n",
    "- Safety-critical applications\n",
    "\n",
    "**Use In-Order Match when:**\n",
    "- Sequence matters but flexibility is acceptable\n",
    "- Extra logging or validation steps are okay\n",
    "- Focus is on correctness over efficiency\n",
    "\n",
    "**Use Any-Order Match when:**\n",
    "- Steps are independent\n",
    "- Order doesn't affect outcome\n",
    "- Parallel execution is possible\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(comparison_md))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Best Practices for Trajectory Evaluation\n\n#### When to Evaluate Trajectories\n\n| Situation | Why |\n|:----------|:----|\n| Debugging unexpected behavior | Identify where agent deviates |\n| Optimizing performance | Find inefficiencies and redundant steps |\n| Ensuring compliance | Validate required workflow steps |\n| Comparing implementations | Benchmark different agent versions |\n\n#### Choosing Evaluation Criteria\n\n| Factor | Consideration |\n|:-------|:--------------|\n| Domain requirements | Some domains require strict order (medical, legal) |\n| Efficiency goals | Balance correctness with performance |\n| Cost constraints | Redundant steps increase API costs |\n\n#### Combining Trajectory and Output Evaluation\n\nEvaluate both trajectory (HOW) and output (WHAT) for complete visibility:\n```python\ncombined_score = (trajectory_score * 0.4) + (output_score * 0.6)\n```\n\n#### Production Monitoring\n\nMonitor: trajectory lengths, tool usage patterns, execution times, failure points."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "You've successfully learned how to evaluate agent trajectories using Strands Evals. You now understand:\n",
    "\n",
    "- **What trajectories are**: Sequences of tool calls and reasoning steps agents use to solve tasks\n",
    "- **Why trajectory evaluation matters**: Understanding HOW agents think, not just WHAT they produce\n",
    "- **Trajectory hierarchy**: Session → Trace → Spans structure in Strands\n",
    "- **Three trajectory patterns**:\n",
    "  - Optimal: Correct tools in correct order\n",
    "  - Suboptimal: Extra or redundant steps\n",
    "  - Incorrect: Wrong tools or wrong order\n",
    "- **Scoring functions**:\n",
    "  - exact_match_scorer: Strict sequence matching\n",
    "  - in_order_match_scorer: Allows extra steps\n",
    "  - any_order_match_scorer: Ignores order\n",
    "- **TrajectoryEvaluator**: LLM-based trajectory assessment with custom rubrics\n",
    "- **Best practices**: When and how to evaluate trajectories effectively\n",
    "\n",
    "Trajectory evaluation is essential for understanding agent behavior, optimizing performance, and ensuring reliable execution. By evaluating both the process (trajectory) and the result (output), you gain complete visibility into agent systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
